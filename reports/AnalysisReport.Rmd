---
title: 'Cyber Security: Safety At Home, Online, and in Life'
author: "Varsha Venkataraman - 240150459 "
date: "`r Sys.Date()`"
output:
  pdf_document: null
  latex_engine: xelatex
  html_document:
    df_print: paged
---
\underline{\textbf{Introduction}}

This report investigates and provides insights on the data collected for the \texttt{Cyber Security:(Safety At Home, Online, and in Life)} course developed by Newcastle University and offered by the Future Learn Platform which is a massive open online course (MOOC).

\underline{\textbf{Business Understanding:}}

The university course team are likely to find some value from this report, with the main beneficiaries being the online course providers. The framework that is used to provide the results and conclusions in the report is the \texttt{Cross Industry Standard for Data Mining (CRISP-DM)}, performing two cycles of the model to produce the results which follow. 

The investigation can provide them in framing the upcoming course structure or modify the existing ones, and rectify the existing issues they are facing with learners.

\underline{\textbf{Success Criteria:}}

The main objective of the report is to identify the areas where the university can improve in getting the right choice of learners and improve the course modules so that the course will also be popular and effective.

\underline{\textbf{Round 01 of the CRISP-DM Cycle}}

With the primary objective in the mind the first question which this report aims to answer is:

\textbf{Research Question:} What is the distribution of employment areas among learners enrolled in the Cyber Security course, and are there any missing data which is in high proportion that affect the insights?

\underline{\textbf{1.1 Data Understanding:}}

For \texttt{phase 1} of \texttt{CRISP-DM},the data file that has the details of learners such as the \texttt{learner id, employment area}, are the primary columns required. The reason for choosing these fields is explained in the feature engineering. The cyber security enrollments file for each period are considered primarily for the first research question. The 

\underline{\textbf{Feature Engineering:}}

For the first research question, its important to have learners id,and to find distribution of employment area of the learners we need to consider the employment area feature. So rest fields are optional for this research question hence removed them for further analysis.

\underline{\textbf{1.2 Exploring the data:}}

After gathering the data file, the next step is to investigate for any data issues. This step is to avoid any potential issues that might arise when we start with the analysis part, Hence its necessary to clean and pre process the data as per our requirement.

When I explored the cyber security enrollment files for different time frames. The data files contained learners Id and their specific 'employment_area', 'highest_education_level' and few more details. But, there were lots of 'Unknown' values in many rows and columns. The 'Unknowns' values created the data to be more weaker to come up with a conclusion as these values cannot be assumed or filled with methods to fill the missing entries.

Few columns had 'Unknown' as a value, but column like 'purchased_statement_at' have many missing data in it and the rows were also left blank. Categorical fields like these are difficult to be filled with data, and we need to consider them to be 'NA' or 'Unknown'.

Also, there were repeated learners id, initially I considered it to be a primary key but when I saw it to be repeated, a doubt of duplicates raised. But, further exploring the repeated values along with its enrolled date in the original data file, a clear understanding was made that the learners rejoined the course at various intervals.

\underline{\textbf{1.3 Data Preparation:}}

The data preparations included five steps in total. The steps includes \texttt{data collection, data cleaning , data integration, data transformation and selecting the data in preparation} for the modelling phase to come next. 

\underline{\textbf{1.3.1 Data Wrangling:}}

\underline{\textbf{1.3.1.1 Data Munging:}}

The data gathered for this research was sourced from Future Learn. The Learner IDs allow for combining of information between different data sheets. The data is collected for the cyber security course for a specific period so there seven different time frames in which the data is collected. 

The data has all the primary details of the learners who joined the course in different time frames, and their specific enrollment time along with their employment area is also gathered.

The \texttt{munge} folder contains files related to data pre-processing steps. This folder includes:

\begin{verbatim}
   -> munge
      |_ 01-dataCleaning.R
      |_ 02-dataIntegration.R
      |_ 03-dataTransformation.R
\end{verbatim}

\underline{\textbf{1.3.1.2 Data Cleaning:}}

Data wrangling is a more specific part of data preparation, focusing on cleaning, restructuring, and transforming raw data into a more useful format which includes the below steps.

\underline{\textbf{1.3.1.2.1 Data Filtering:}}

In data cleaning, I filtered out the required columns alone and removed the unwanted columns from the data files. In the enrollment file , I only considered 'learner_id', 'employment_area' and eliminated rest of the columns. The reason to consider these specific columns is because the learner_id from which, I will get very unique information about the learners and it will act as a primary key here. The employment area is considered as my research question is bounded by it and I will need to do every analysis considering the employment area of the learner

\underline{\textbf{1.3.1.2.3 Handling Missing Values:}}

I also replaced the empty rows with 'NA' for uniformity and to fill the blank space. Here we are not able to follow any of the methods such as to replace with mean , mode or median for the missing data as all are unique values and its hard to follow any of the existing methods to replace hence went with the way of filling it with the unknown value.

\textbf{Why 'NA' instead of 'Unknown' :}

The \texttt{NA is a standardized} way to represent missing data in R (and other statistical tools). Most functions that handle missing data recognize NA, making data processing more seamless. Using “Unknown” as a placeholder may lead to misinterpretation by functions that expect missing values as NA. 

Most \texttt{statistical models, transformations, and data wrangling techniques treat NA values appropriately}, either by ignoring or imputing them as necessary. Having “Unknown” in place of NA might bias analyses, as it is recognized as text rather than as a missing value.

\underline{\textbf{1.3.1.4 Data Integration:}}

In data Integration, In figure 1, there are different files which are pre processed and data is cleaned, Now I combined the related files altogether into a single file for each group. So, the figure 2 represents the combination of all related files. 

\begin{minipage}{0.45\textwidth}
\begin{verbatim}
-> cache
    |_ cyber.security.1_enrolments.RData
    |_ cyber.security.2_enrolments.RData
    |_ cyber.security.3_enrolments.RData
    |_ cyber.security.4_enrolments.RData
    |_ cyber.security.5_enrolments.RData
    |_ cyber.security.6_enrolments.RData
    |_ cyber.security.7_enrolments.RData
\end{verbatim}
\end{minipage} \hfill
\begin{minipage}{0.55\textwidth}
\begin{verbatim}
    -> cache
        |_ combined_enrolment_data.RData
\end{verbatim}
\end{minipage}

\underline{\textbf{1.3.1.5 Data Transformation:}}

In this part, I re-coded the employment_area row values with standardized categorical labels. This transformation is usually done when you want to standardize or simplify categorical values, making them easier to analyze or interpret.

```{r setup,message=FALSE, warning=FALSE, echo = FALSE}
knitr::opts_chunk$set(echo = TRUE)  # Disable caching globally
knitr::opts_knit$set(root.dir = normalizePath(".."))
options(repos = c(CRAN = "https://cran.rstudio.com/"))
```
```{r,message=FALSE, warning=FALSE, echo = FALSE}
library(ProjectTemplate)
load.project()
```
```{r,message=FALSE, warning=FALSE, echo = FALSE}
replacement_table <- data.frame(
  Old_Value = c(
    "accountancy_banking_and_finance", "armed_forces_and_emergency_services", "business_consulting_and_management", 
    "charities_and_voluntary_work", "creative_arts_and_culture", "energy_and_utilities", 
    "engineering_and_manufacturing", "environment_and_agriculture", "health_and_social_care", 
    "hospitality_tourism_and_sport", "it_and_information_services", "law", 
    "marketing_advertising_and_pr", "media_and_publishing", "property_and_construction", 
    "public_sector", "recruitment_and_pr", "retail_and_sales", "science_and_pharmaceuticals", 
    "teaching_and_education", "transport_and_logistics"
  ),
  New_Value = c(
    "Finance", "Defense", "Consulting", "Charity", "Arts", "Energy", 
    "Engineering", "Environment", "Healthcare", "Hospitality", "IT", 
    "Law", "Marketing", "Media", "Construction", "Public", "Recruitment", 
    "Retail", "Science", "Education", "Logistics"
  )
)

first_part <- replacement_table[1:11, ]
second_part <- replacement_table[12:nrow(replacement_table), ]
second_part <- rbind(second_part, data.frame(Old_Value = "", New_Value = ""))
combined_table <- cbind(first_part, second_part)
kable(combined_table, col.names = c("Old Value", "New Value", "Old Value", "New Value")) %>%
  kable_styling(full_width = FALSE, position = "center", latex_options = "striped") %>%
  row_spec(0, bold = TRUE, color = "black", background = "#D3D3D3")
  
```

\underline{\textbf{1.4 Modelling and Visualizations:}}

The below first bar plot 'Enrollment in Cyber Security course by Employment Area' represents the 'Employment Area' of the learners who enrolled in the cyber security course in the university. The y axis has the different type of 'Employment Area' of the learners. The x axis has the number of enrollments in the cyber security course which has the range from 0 to 1500. 

From the visualization we can conclude that the learners from IT industry has the maximum enrollment and the learners from the recruitment industry has the least enrollment. It is very obvious that the IT field is related to the course, but its surprising that the Finance area is standing seventh in the column. 

The cyber security has important role in the finance and banking area as many fraudulent acts occurs in this area. 

The second bar plot titled 'Number of re-joiners by Employment Area' depicts the maximum number of re-joiners from different employment area. Its very evident that its from 'IT' field there are maximum number of re-joiners. Also, the number of re-joiners is not propotional to the number of enrollments in the course base on employment area.

```{r,message=FALSE, warning=FALSE, echo = FALSE,fig.height=4,fig.width=5,fig.align='center'}
filtered_data <- combined_enrolment_data %>%
    filter(!is.na(employment_area))
enrollment_plot <- ggplot(filtered_data, aes(x = reorder(employment_area, employment_area, function(x) -length(x)))) +
    geom_bar(fill = "#4682B4", color = "black", width = 0.7) +  # Steel blue fill with black border for contrast
    geom_text(stat = "count", aes(label = ..count..), vjust = -0.3, size = 3.5, color = "black") +  # Data labels above bars
    labs(
        title = "Enrollment in Cyber Security Course by Employment Area",
        subtitle = "Distribution of enrollments across various employment areas",
        x = "Employment Area",
        y = "Number of Enrollments"
    ) +
    theme_minimal(base_size = 14) +  # Increase base font size for readability
    theme(
        plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),  # Center and bold title
        plot.subtitle = element_text(hjust = 0.5, size = 12, color = "gray40"),  # Center subtitle
        axis.title.x = element_text(size = 12, margin = margin(t = 10)),  # Add margin above x-axis label
        axis.title.y = element_text(size = 12, margin = margin(r = 10)),  # Add margin to the right of y-axis label
        axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1, size = 10, color = "gray20"),  # Rotate x-axis labels
        panel.grid.major.y = element_line(color = "gray80", size = 0.5),  # Custom grid line for y-axis
        axis.ticks.x = element_blank()  # Remove x-axis ticks for a cleaner look
    ) +
    scale_y_continuous(expand = expansion(mult = c(0, 0.1)))  # Adjust y-axis for space above bars

enrollment_plot
ggsave("graphs/enrollment_by_employment_area.png", plot = enrollment_plot, width = 10, height = 6)
```

```{r,message=FALSE, warning=FALSE, echo = FALSE,fig.height=4,fig.width=5,fig.align='center'}
rejoiners_data <- duplicate_counts %>%
  inner_join(combined_enrolment_data, by = "learner_id")

# Step 2: Filter to only include rejoiners (count > 1)
rejoiners_filtered <- rejoiners_data %>%
  filter(count > 1)

# Step 3: Summarize rejoiner counts by employment area
rejoiners_summary <- rejoiners_filtered %>%
  group_by(employment_area) %>%
  summarise(total_rejoiners = n()) %>%
  arrange(desc(total_rejoiners))
rejoiners_summary_filtered <- rejoiners_summary %>% 
  filter(!is.na(employment_area))
rejoiners_summary_employment_area <- ggplot(rejoiners_summary_filtered, aes(x = reorder(employment_area, -total_rejoiners), y = total_rejoiners)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black") +
  labs(
    title = "Number of Rejoiners by Employment Area",
    x = "Employment Area",
    y = "Total Rejoiners"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        plot.title = element_text(hjust = 0.5, size = 14, face = "bold"))
rejoiners_summary_employment_area
ggsave("graphs/rejoiners_summary_employment_area.png", plot = rejoiners_summary_employment_area, width = 10, height = 6)
```
```{r,message=FALSE, warning=FALSE, echo = FALSE}
total_learners <- nrow(combined_enrolment_data)
total_learners_df <- data.frame(
  Metric = "Total Learners",
  Value = total_learners
)
# Unique Learners
unique_learners <- n_distinct(combined_enrolment_data$learner_id)
unique_learners_df <- data.frame(
  Metric = "Unique Learners",
  Value = unique_learners
)
# Combine the tables side by side using `cbind`
combined_table <- cbind(total_learners_df, unique_learners_df)
# Display the result in a side-by-side table format using kable
kable(combined_table, caption = "Learner Metrics") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

With respect to the above Table 1, the total number of learners who are enrolled in the cyber security course is 63,248 of them. Looking at the pie chart below which has the percentage value for the learners per employment area. We can conclude that we have the employment area information only for 9% of the learners only.

The remaining 91% (roughly 57,556 learners) do not have employment area information. Because of which we cannot come up with 100% accuracy which area of employers take up this cyber security course. 

There are around \texttt{63,248 learners} with respect to the Table 1, who enrolled altogether in the cyber security course. But the unique number of learners are only \texttt{35,225} according to Table 1. Which means the rest \texttt{28,023} are either duplicate or re-joiners. 
```{r,message=FALSE, warning=FALSE, echo = FALSE,fig.height=6,fig.width=6,fig.align='center'}
colors <- colorRampPalette(brewer.pal(9, "Set1"))(22)
summary_data <- combined_enrolment_data %>%
    count(employment_area) %>%
    rename(Count = n) %>%
    add_row(employment_area = "Missing", Count = sum(is.na(combined_enrolment_data$employment_area))) %>%
    add_row(employment_area = "Total", Count = nrow(combined_enrolment_data)) %>%
    filter(employment_area != "Total")  # Exclude the total row for pie chart clarity

# Assign custom labels for the segments
summary_data$label <- ifelse(summary_data$employment_area == "it_and_information_services", "IT", 
                             ifelse(summary_data$employment_area == "Missing", "Missing Data", summary_data$employment_area))
summary_data <- summary_data %>%
    mutate(percentage = Count / sum(Count) * 100)
# Determine the maximum count value for outline (which corresponds to "IT" or "Missing Data")
max_value_row <- which.max(summary_data$Count)

# Create the pie chart
pieChart_MissingLearners <- ggplot(summary_data, aes(x = "", y = Count, fill = label)) +
    geom_bar(stat = "identity", width = 1, color = ifelse(1:nrow(summary_data) == max_value_row, "black", NA), size = 1.2) +  # Add outline for max value
    coord_polar(theta = "y") +
    geom_text(aes(label = ifelse(1:nrow(summary_data) == max_value_row, 
                                 paste0(label, "\n", round(percentage), "%"), 
                                 "")), 
              position = position_stack(vjust = 0.5), size = 5, color = "white") +
    theme_minimal() +
    labs(title = "Learners per Employment Area", fill = "Employment Area") +
    theme(
        axis.title = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        plot.title = element_text(hjust = 0.5, size = 12, face = "bold"),  # Center and bold title
        legend.title = element_text(face = "bold", size = 12),  # Bold legend title
        legend.text = element_text(size = 10),  # Adjust legend text size
        legend.position = "right",  # Move legend to the right side
        legend.key.size = unit(0.5, "cm")  # Reduce legend key size for compactness
    ) +
    scale_fill_manual(values = colors) +  # Apply the custom color palette
    guides(
        fill = guide_legend(title.position = "top", title.hjust = 0.5)  # Center the legend title
    )

# Display and save the pie chart
pieChart_MissingLearners
ggsave("graphs/pieChart_MissingLearners_employment_area.png", plot = pieChart_MissingLearners, width = 10, height = 6)

```

```{r,message=FALSE, warning=FALSE, echo = FALSE,fig.height=5,fig.width=5,fig.align='center'}
learner_count <- combined_enrolment_data %>%
  filter(!is.na(employment_area)) %>%  # Remove rows where employment_area is NA
  group_by(employment_area) %>%
  summarise(count = n_distinct(learner_id)) %>%
  mutate(percentage = count / sum(count) * 100)

# Identify the maximum percentage
max_percentage <- learner_count %>%
  filter(percentage == max(percentage)) %>%
  pull(employment_area)

# Choose a color palette from RColorBrewer
colors <- brewer.pal(n = nrow(learner_count), name = "Set3")

# Plot the pie chart with highlighted maximum value
learners_employment_area <- ggplot(learner_count, aes(x = '', y = percentage, fill = employment_area)) +
  geom_bar(stat = 'identity', width = 1) +
  coord_polar(theta = 'y') +
  labs(title = 'Learners per Employment Area') +
  theme_void() +
  theme(legend.title = element_blank(), 
        plot.title = element_text(hjust = 0.5, size = 11, face = "bold"),
        legend.position = "right") +
  scale_fill_manual(values = c(
    setNames(c("darkred", rep(NA, nrow(learner_count) - 1)), 
             c(max_percentage, setdiff(learner_count$employment_area, max_percentage)))
  )) +
  guides(fill = guide_legend(override.aes = list(color = "black", size = 2))) 
learners_employment_area
ggsave("graphs/learners_employment_area.png", plot = learners_employment_area, width = 10, height = 6)

```



\underline{\textbf{1.5 Evaluation :}}

The goal of first research question is not completely achieved as there are 91% of missing data so we cannot come to a conclusion with cent percent accuracy that the IT industry has the most number of learners for the cyber security course. With the dataset we have excluding the missing data, we can make a conclusion that the IT industry has the maximum distribution of learners. 

We need to ensure to have the enrollment details completely collected before enrolling and starting with the course, as it is always necessary to have the basic enrollment details of the learners.

\underline{\textbf{Round 02 of the CRISP-DM Cycle}}

With the secondary objective of the report, I am investigating on number of re-joiners, I am trying to understand the reason for them to quit and rejoin. Also, to gain some insights so that we can avoid re-joiners and modify the course modules accordingly to make it efficient to complete in the first schedule, if the reasons are stated because of the course structure. 

\textbf{Research Question:} What is the primary reason for re-enrollment based on the employment area? What potential improvement can be done to the course to help learners complete the course without rejoining?

\underline{\textbf{2.1 Data Understanding:}}

For phase 2 of CRISP-DM, to make an analysis for the number of re-joiners, I first need to know the count of re-joiners and their duplicate learners id. Also, to know the primary reason to leave the course its required to gather the unique reasons stated by the learners to quit. So for this I am considering the leaving_survey_response data and also the course enrollment data file and video statistics data file.

\underline{\textbf{2.2 Exploring the data:}}

Firstly, the course enrollment data is analysed in the first cycle and number of unique and repeated learners count is gathered. Looking into the 'leaving_survey_response data' we can gather the unique reasons for the learners to leave the course. So looking at the reasons for the learners to leave which is a categorical data, the options that were widely opted contained 'time'. Also, to ensure the course structure, I analysed the video statistics data and analysed the number of hours it takes to complete a course also the module structure. The time were in seconds and also each module had different time duration. But, the total time for the course modules looked same. Now, let's start with the data preparation part.

\underline{\textbf{2.3 Data Preparation:}}

\underline{\textbf{2.3.1 Data Wrangling:}}

\underline{\textbf{2.3.1.2 Data Cleaning and Filtering:}}

In data cleaning, I filtered out the required columns alone and removed the unwanted columns from the data file. In the survey response file , I only considered 'learner_id', 'left_at', 'leaving_reason'. For the video statistics data frames I filtered out only the time and maintaining the value in seconds and later will convert it to hours during data transformation.

\underline{\textbf{2.3.1.2.5 Feature Engineering:}}

For this research question, its important to have learners id,and to find the reason for them to leave we need to have the 'leaving_reasons' field. So rest fields are optional for this research question hence removed them for further analysis. Also in the video statistics data frames I added up all the time duration and created a new column to address how many hours is taken for each cyber security time frame course. The reason to exclude the modules is, looking into the reasons stated my learners for leaving the course mainly had 'time related issues' so I decided to focus on the time duration for this research question.

\underline{\textbf{2.3.1.2.2 Handling Missing Values:}}

Moreover the first three leaving-survey-responses files did not even have any datas the file size was less in bytes. So, I did not consider these files and started with the files that had data.

I also replaced the empty rows with 'NA' for uniformity and to fill the blank space and aslo as stated in the first cycle its pretty easier to use built in functions. Here we are not able to follow any of the methods such as to replace with mean , mode or median for the missing datas as all are unique values and its hard to follow any of the existing methods to replace hence went with the way of filling it with the unknown value.

\underline{\textbf{2.3.1.2.3 Data Integration:}}

In data Integration, In figure 1, there are different files which are pre processed and data is cleaned, Now I combined the related files altogether into a single file for each group. So, the figure 2 represents the combination of all related files. 

\begin{minipage}{0.45\textwidth}
\begin{verbatim}
-> cache
   |-> preData
         |_cyber.security.4_leaving.survey.responses.RData
         |_cyber.security.5_leaving.survey.responses.RData
         |_cyber_security.6_leaving-survey-responses.RData
         |_cyber_security.7_leaving-survey-responses.RData
\end{verbatim}
\begin{verbatim}
-> cache
   |_combined_leaving_survey_data.RData
\end{verbatim}
\end{minipage}

\begin{minipage}{0.45\textwidth}
\begin{verbatim}
-> cache
   |-> preData
         |_cyber.security.3_video.stats
         |_cyber.security.4_video.stats
         |_cyber.security.5_video.stats
         |_cyber.security.6_video.stats
         |_cyber.security.7_video.stats
\end{verbatim}
\begin{verbatim}
-> cache
   |_combined_cyber.security_video.stats.RData
\end{verbatim}
\end{minipage}

\underline{\textbf{2.4 Modelling and Visualizations:}}

```{r,message=FALSE , warning=FALSE, echo = FALSE}
duplicate_counts <- duplicate_counts %>%
  mutate(rejoin_bucket = case_when(
    count >= 2 & count <= 3 ~ "Q1(2-3)",
    count >= 4 & count <= 5 ~ "Q2(4-5)",
    count >= 6 & count <= 7 ~ "Q3(6-7)",
    count > 8 ~ "Q4",
    TRUE ~ "Q1"  # default for any count less than 2
  ))
# Count the number of learners in each bucket
bucket_counts <- duplicate_counts %>%
  group_by(rejoin_bucket) %>%
  summarise(learner_count = n())
rejoiner_plot <- ggplot(bucket_counts, aes(x = rejoin_bucket, y = learner_count, fill = rejoin_bucket)) +
  geom_bar(stat = "identity", color = "black", width = 0.6) +  # Black border and adjusted bar width
  scale_fill_manual(values = c("Q1(2-3)" = "#A1D99B", "Q2(4-5)" = "#41AB5D", "Q3(6-7)" = "#238B45", "Q4" = "#005A32", "Q1" = "#C7E9C0")) +  # Custom color palette
  geom_text(aes(label = learner_count), vjust = -0.5, size = 3.5, color = "black") +  # Add data labels above bars
  labs(
    title = "Distribution of Learners Rejoining the Course",
    subtitle = "Classified by Rejoin Frequency Buckets",
    y = "Number of Learners",
    x = ""
  ) +
  theme_minimal(base_size = 14) +  # Increase base font size for readability
  theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),  # Bold and center-align title
    plot.subtitle = element_text(hjust = 0.5, size = 12, color = "gray50"),  # Subtitle styling
    axis.title.y = element_text(size = 12, face = "italic"),  # Italicize y-axis label
    axis.ticks.x = element_blank(),  # Remove x-axis ticks for a cleaner look
    legend.position = "none"  # Hide legend if each bucket is uniquely labeled
  ) +
  scale_y_continuous(expand = expansion(mult = c(0, 0.1)))  # Add space above bars for labels
rejoiner_plot
ggsave("graphs/rejoiner_plot.png", plot = pieChart_MissingLearners, width = 10, height = 6)
```

To start with the visualization, the first bar plot title 'Distribution of learners rejoining the course' here I bucketed the count of re-joiners as groups, ( Q1 has the count 2 and 3 re-joiners, Q2 has the count of count 4 and 5 re-joiner, Q3 has the count of 6 and 7 re-joiners). The x axis has the number of rejoiners count and the y axis has the number of learners. Looking at the plot we can come to a conclusion that there are maximum 2-3 re-joiners for the course.

Since there are many number of re-joiners for the cyber security course. Now, looking at the survey response collected from the learners for leaving the course I have tabled number of learners reasons to leave the course with unique reasons and its total count chosen by the learners.

Looking at the below tabular column I can see the maximum number of learners had opted saying 'They do not have enough time'. Also, 40 learners opted for 'The course required more time' since both are time related I added the values and the count is 143. There are learners who are not satisfied with the course and few found it hard and few found it very easy but there count are very less when compared to learners who choose time as main issue.

```{r,message=FALSE, warning=FALSE, echo = FALSE,fig.height=4,fig.width=5,fig.align='center'}
unique_leaving_reasons_count <- combined_leaving_survey_data %>%
  count(leaving_reason) %>%
  arrange(desc(n))

leaving_reasons_table <- kable(unique_leaving_reasons_count, col.names = c("Unique Leaving Reason", "Leaving Reason Count"), booktabs = TRUE, format = "latex", align = c("l", "c")) %>%
  kable_styling(latex_options = c("striped", "hold_position", "scale_down")) %>%
  row_spec(which.max(unique_leaving_reasons_count$n), bold = TRUE)
leaving_reasons_table

video_duration_summary <- combined_data_video_stats %>%
  group_by(cyber_security) %>%
  summarise(total_duration_hours = sum(video_duration) / 60)

video_duration_table <- kable(video_duration_summary, col.names = c("Cyber Security Level", "Total Duration (hours)"), format = "latex", booktabs = TRUE) %>%
  kable_styling(latex_options = c("striped", "hold_position", "scale_down")) %>%
  column_spec(2, bold = TRUE, color = "blue") %>%  # Emphasize the duration column
  row_spec(0, bold = TRUE, background = "lightgray")  # Bold and highlight header row
video_duration_table
```

Since, the maximum reason was time constraints, I calculated the total hours taken for the course to be completed it is 50.05. Hence one main action by the course team need to take into consideration is to reduce the total time taken for the completion. Keeping in mind there are a lot of missing datas, we need to specifically see the reason to leave the course by the learners particularly from each employment area.

Looking at the below table, we can see the 'Arts' , 'Consulting' ,'Education', and 'Public' field related learners are feeling time related issues. Adding to it, we inffered that 'IT' field learners are more learners and re-joiners for the course so to see specific reasons choosen by the learners will also add value to the course team to take neccessary actions.

```{r,message=FALSE, warning=FALSE, echo = FALSE,fig.height=4,fig.width=5,fig.align='center'}
employment_area_reason_counts <- combined_leaving_survey_data %>%
  inner_join(combined_enrolment_data, by = "learner_id") %>%
  drop_na(employment_area, leaving_reason) %>%
  group_by(leaving_reason, employment_area) %>%
  summarise(count = n(), .groups = 'drop')

# For each leaving_reason, find the employment_area with the maximum count
max_employment_area_reason <- employment_area_reason_counts %>%
  group_by(leaving_reason) %>%
  filter(count == max(count)) %>%
  ungroup() %>%
  select(leaving_reason, employment_area, count)

# Display the results in a table format
max_employment_area_reason_table <- kable(max_employment_area_reason, 
                                          col.names = c("Leaving Reason", "Employment Area", "Count"),
                                          booktabs = TRUE, format = "latex", align = c("l", "c", "c"), longtable = TRUE) %>%
  kable_styling(latex_options = c("striped", "hold_position", "scale_down"))

max_employment_area_reason_table
```

Looking at the above table we can see that, The learners from 'IT' employment area had choosen reasons like 'The course was too hard' , 'The course was not upto their expectation' , 'They prefer not say' and 'Other'. A suggestion to the course team would be if the learner is choosing 'other' to give an option to the learners to fill the reason so that it will help to know the exact reason. But with the current available data a decision that the course modules needed to be modified so that the learner from the 'IT' field will have complete satisfaction.

In conclusion it is stated that most of the learners feel that the course is very lengthy that they do not find enough time to complete. Which is why they are re-joining it or maybe the course is framed perfect its the learners are not able to frame time for learning.

If this total course time is minimized or divided as 25 hours for video materials and the rest modules as pdf or document to self study it might minimize the learners to leave the course.

Since, more learners are from 'IT' field we can collect the form as why the course is hard and why it did not meet their expectations with which we can proceed to alter the modules.

```{r,message=FALSE, warning=FALSE, echo = FALSE,fig.height=4,fig.width=5,fig.align='center'}
sector <- "IT Sector"
learners_IT <- 1357
rejoiners_IT <- 300

learners_rejoiners_data <- data.frame(
  Category = c("Learners", "Rejoiners"),
  Count = c(learners_IT, rejoiners_IT)
)

# Bar plot for Learners vs Rejoiners
bar_plot <- ggplot(learners_rejoiners_data, aes(x = Category, y = Count, fill = Category)) +
  geom_bar(stat = "identity") +
  labs(title = "Learners vs Rejoiners in IT Sector", x = "Category", y = "Count") +
  theme_minimal() +
  theme(legend.position = "top",  # Move legend to the top
        legend.title = element_blank(),  # Remove legend title
        legend.key.size = unit(0.6, "cm"))  # Adjust legend key size

bar_plot
```

\underline{\textbf{2.5 Evaluation :}}

The primary goal of the second research question is to find the main reason for the learners to leave the course which we concluded as the 'Time required', and the second sub part of the questions finding is the 'IT' sector  area has the majority of the re-joiners and addressing the potential leaving reasons and rectifying it so that the course modules are improved.

\underline{\textbf{Final Phase Deployment: }}

The final phase of this CRISP-DM is the deployment which includes the analysis and also my presentation for the insights derived from the dataset given, hoping this will add up value to the course and also help the stakeholders to improve the course modules and rectify the existing issues.

The features chosen to be focused are the employment area and the reason for leaving the course. The main ideology was to find and reduce the number of re-joiners and help the learners complete it addressing the reason for them to quit. The visuals that completely relate to conclusions are 'Distribution of learner rejoining the course' and 'Unique leaving reasons'.

I have chosen to include the comparison bar plots of number of learners and re-joiners based on employment area to identify which employment area contribute maximum learners to the course. A tabular column to have the unique reasons and the leaving reason count to understand the main reason for the learners to quit. A tabular column with the employment area along with the count on leaving reason to get to know what the learners from various employment area feel like so that we can address all the issue for a betterment of the course.

These informative graphics will help the stakeholders to come up with an idea to resolve the existing issues and enhance the course for a better level.


