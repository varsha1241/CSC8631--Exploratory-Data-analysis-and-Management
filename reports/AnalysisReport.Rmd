---
title: "Cyber Security: Safety At Home, Online, and in Life"
author: "Varsha Venkataraman - 240150459 "
date: "`r Sys.Date()`"
output: 
    pdf_document:
    latex_engine: xelatex
---
\textbf{Introduction}

This report investigates and provides insights on the data set collected for the Cyber Security: Safety At Home, Online, and in Life course developed by Newcastle University and offered by the FutureLearn Platfrom which is a massive open online course (MOOC).

The university course team are likely to find some value from this report, with the main beneficiaries being the online course providers. The framework that is used to provide the results and conclusions in the report is the Cross Industry Standard for Data Mining (CRISP-DM), performing two cycles of the model to produce the results which follow.

\textbf{Round 01 of the CRISP-DM Cycle}

With the primary objective in the mind the first question which this report aims to answer is:

\textbf{Research Question:} How many unique learners enrolled in the Cyber Security course, and what is the extent of duplicate enrollments across different cycles?

\textbf{Data Understanding:} 
For phase 1 of CRISP-DM,the data set that has the details of learners such as the learner id, enrollment date, and some more information is required.The cyber security enrollments file for each period is to be considered. 

\textbf{Data Collection:}
The data gathered for this research was sourced from FutureLearn. The Learner IDs allow for combining of information between different data sheets. The data is collecetd for the cyber security course for a specific period so there seven different time frames in which the data is collected. 

\textbf{Exploring the data:}

After gathering the dataset the next step is to investigate for any data issues. This step is to avoid any potential issues that might arise when we start with the analysis part, Hence its necessary to clean and pre process the dataset as per our requirement.

When I explored the cyber security enrollment files for the cyber security for different time frames. The dataset contained learners Id and their specific their 'employment_area', 'highest_education_level' and few more details. But, there were lots of 'Unknown' values in many rows and columns. The 'Unknowns' values created the data to be more weaker to come up with a conclusion as these values cannot be assumed or filled with methods to fill the missing entries.

Few columns had 'Unknown' as a value , but column like 'purchased_statement_at' have many missing data in it and the rows were also left blank. Categorical fields like these are difficult to fill with data, and we need to consider them to be 'NA' or 'Unknown'.

Also, there were repeated learners id , initialy i considered it to be a primary key but when I saw it to be repeated, a doubt of duplicates araised.But, further exploring the repeated values along with its enrolled date, a clear understanding was made that the learners rejoined the course at various intervals.

\textbf{Data Preparation:}

Continuing on to next phase of the CRISP-DM model that is data preparation. This has sub divisions like data cleaning , data integration, data transformation and selecting the data in preparation for the modelling phase to come next. 

The \texttt{munge} folder contains files related to data pre-processing steps. This folder includes:

\begin{verbatim}
   -> munge
      |_ 01-dataCleaning.R
      |_ 02-dataIntegration.R
      |_ 03-dataTransformation.R
\end{verbatim}
 
\textbf{Data Cleaning:}

In data cleaning, I filterd out the required columns alone and removed the unwanted columns from the dataset. In the enrolment file , I only considered 'learner_id', 'highest_education_level', 'employment_area' and eliminated rest of the columns.

The 'enrolled_at' column had the format of date and time, I filtered out only date from it. I also replaced the empty rows with 'NA' for uniformity and to fill the blank space. Here we are not able to follow any of the methods such as to replace with mean , mode or median for the missing datas as all are unique values and its hard to follow any of the existing methods to replace hence went with the way of filling it with the unknown value.

```{r setup,message=FALSE, warning=FALSE, echo = FALSE}
knitr::opts_chunk$set(echo = TRUE)  # Disable caching globally
knitr::opts_knit$set(root.dir = normalizePath(".."))
```
```{r,message=FALSE, warning=FALSE, echo = FALSE}
library(ProjectTemplate)
load.project()
```
```{r,message=FALSE, warning=FALSE, echo = FALSE}
filtered_data <- combined_data %>%
    filter(!is.na(employment_area))
ggplot(filtered_data, aes(x = reorder(employment_area, employment_area, function(x) -length(x)))) +
    geom_bar(fill = "steelblue") +
    labs(
        title = "Enrollment in Cyber Security Course by Employment Area",
        x = "Employment Area",
        y = "Number of Enrollments"
    ) +
    theme_minimal() +
    theme(
        axis.text.x = element_text(angle = 45, hjust = 1, size = 8),  # Adjust font size and angle
        plot.title = element_text(hjust = 0.5)
    ) +
    scale_y_continuous(expand = expansion(mult = c(0, 0.05)))
```

The above bar plot represents the 'Employment Area' of the learners who enrolled in the cyber security course in the university. The y axis has the different type of 'Employment Area' of the learners. The x axis has the number of enrollments in the cyber security course which has the range from 0 to 1500. 

From the visualization we can conclude that the learners from IT industry has the maximum enrollment and the learners from the recruitment industry has the least enrollment. It is very obvious that the IT field is related to the course, but its surprising that the Finance area is standing seventh in the column. 

The cyber security has important role in the finance and banking area as many fraudulent acts occurs in this area. 

```{r,message=FALSE, warning=FALSE, echo = FALSE}
total_learners <- nrow(combined_data)
total_learners_df <- data.frame(
  Metric = "Total Learners",
  Value = total_learners
)
# Unique Learners
unique_learners <- n_distinct(combined_data$learner_id)
unique_learners_df <- data.frame(
  Metric = "Unique Learners",
  Value = unique_learners
)
# Combine the tables side by side using `cbind`
combined_table <- cbind(total_learners_df, unique_learners_df)
# Display the result in a side-by-side table format using kable
kable(combined_table, caption = "Learner Metrics") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

```{r,message=FALSE, warning=FALSE, echo = FALSE}
unique_learners <- n_distinct(combined_data$learner_id)

# Create a data frame for displaying the count of unique learners
unique_learners_df <- data.frame(
  Metric = "Unique Learners",
  Value = unique_learners
)
# Display the result in a table format using kable
kable(unique_learners_df, caption = "Number of Unique Learners")
```

With respect to the above Table 1, the total number of learners who are enrolled in the cyber security course is 63,248 of them. Looking at the pie chart below which has the percentage value for the learners per employment area. We can conclude that we have the employment area information only for 9% of the learners only.

```{r,message=FALSE, warning=FALSE, echo = FALSE,fig.height=5,fig.width=5,fig.align='center'}
colors <- colorRampPalette(brewer.pal(9, "Set1"))(22)
summary_data <- combined_data %>%
    count(employment_area) %>%
    rename(Count = n) %>%
    add_row(employment_area = "Missing", Count = sum(is.na(combined_data$employment_area))) %>%
    add_row(employment_area = "Total", Count = nrow(combined_data)) %>%
    filter(employment_area != "Total")  # Exclude the total row for pie chart clarity

# Assign custom labels for the segments
summary_data$label <- ifelse(summary_data$employment_area == "it_and_information_services", "IT", 
                             ifelse(summary_data$employment_area == "Missing", "Missing Data", summary_data$employment_area))
summary_data <- summary_data %>%
    mutate(percentage = Count / sum(Count) * 100)
# Determine the maximum count value for outline (which corresponds to "IT" or "Missing Data")
max_value_row <- which.max(summary_data$Count)
# Plot the pie chart
ggplot(summary_data, aes(x = "", y = Count, fill = label)) +
    geom_bar(stat = "identity", width = 1, color = ifelse(1:nrow(summary_data) == max_value_row, "black", NA), size = 1.2) +  # Add outline for max value
    coord_polar(theta = "y") +
    geom_text(aes(label = ifelse(1:nrow(summary_data) == max_value_row, 
                                 paste0(label, "\n", round(percentage), "%"), 
                                 "")), 
              position = position_stack(vjust = 0.5), size = 5, color = "white") +
    theme_minimal() +
    labs(title = "Learners per Employment Area", fill = "Employment Area") +
    theme(
        axis.title = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        plot.title = element_text(hjust = 0.5)
    ) +
    scale_fill_manual(values = colors) +  # Apply the custom color palette
    guides(fill = guide_legend(title.position = "top", title.hjust = 0.5, label.position = "right"))
```

The remaining 91% (roughly 57,556 learners) do not have employment area information. Because of which we cannot come up with which area of employers take up this cyber security course. 

There are around 63,248 learners with respect to the Table 1, who enrolled altogether in the cyber security course. But the unique number of learners are only 35,225 according to Table 1. Which means the rest 28,023 are either duplicate or re-joiners. 

So to investigate on this I am trying to plot a visualization where I have grouped the re-joiners 2-4 as one bucket and 5-8 rejoining count learners as another bucket. And from the visualization below we can conclude that there are more number of re-joiners who are coming under the bucket count 2-4. 

```{r,message=FALSE, warning=FALSE, echo = FALSE,fig.height=4,fig.width=5,fig.align='center'}
duplicate_counts <- duplicate_counts %>%
  mutate(rejoin_bucket = case_when(
    count >= 2 & count <= 3 ~ "Q1(2-3)",
    count >= 4 & count <= 5 ~ "Q2(4-5)",
    count >= 6 & count <= 7 ~ "Q3(6-7)",
    count > 8 ~ "Q4",
    TRUE ~ "Q1"  # default for any count less than 2
  ))
# Count the number of learners in each bucket
bucket_counts <- duplicate_counts %>%
  group_by(rejoin_bucket) %>%
  summarise(learner_count = n())
# Plotting the bucket counts as a bar plot
ggplot(bucket_counts, aes(x = rejoin_bucket, y = learner_count, fill = rejoin_bucket)) +
  geom_bar(stat = "identity") +
  scale_fill_brewer(palette = "Set3") +
  labs(
    title = "Learners Rejoining the Course",
    y = "Learner Count",
    x = " "
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),  # Center the plot title
    axis.text.x = element_text(hjust = 1),  # Rotate x-axis labels for better readability
    axis.ticks.x = element_blank()  # Remove x-axis ticks for a cleaner look
  )
```

Since there are many number of re-joiners for the cyber security course. Now, looking at the survey response collected from the learners for leaving the course I have tabled number of learners reasons to leave the course with unique reasons and its total count chosen by the learners.

```{r,message=FALSE, warning=FALSE, echo = FALSE}
unique_leaving_reasons_count <- duplicates_data_leaving_survey_responses %>%
  count(leaving_reason) %>%    # Count occurrences of each leaving reason
  arrange(leaving_reason)      # Optionally, arrange alphabetically
# Display the unique leaving reasons with their counts in a table format using kable
kable(unique_leaving_reasons_count, col.names = c("Unique Leaving Reason", "Count"))
```

From the above table it is stated that most of the learners feel that the course is very lengthy that they do not find enough time to complete. Which is why they are re-joining it or maybe the course is framed perfect its the learners are not able to frame time for learning.

Nearly 144 learners selected 'I prefer not to say' and 'Others' and 40 of them selected 'The course required more time than I realized' which altogether sums up 359 of them feel like time is the problem. Only 72 learners expectations did not match with the course and 26 of them found it hard.

Looking at the reasons for the learners to leave the course, The below tabular has the details of number of hours the course counts in total, so with respect to this we can conclude the total time taken by the course modules is 50.05 in hours. 

If this is minimised or divided as 25 hours for video materials and the rest modules as pdf or document to self study it might minimise the learners to leave the course.

```{r,message=FALSE, warning=FALSE, echo = FALSE,fig.height=5,fig.width=5,fig.align='center'}
# Summarise the data and calculate the total_duration_hours in hours
video_duration_summary <- combined_cleaned_video_data %>%
  group_by(cyber_security) %>%
  summarise(total_duration_hours = sum(video_duration) / 60)  
kable(video_duration_summary, col.names = c("Cyber Security Level", "Total Duration (hours)"))
```

